{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import pandas as pd\n",
    "from string import digits\n",
    "import explore\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = acquire.get_github_geology_results(cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Clean Data Function ###############################\n",
    "\n",
    "def basic_clean(string):\n",
    "    '''\n",
    "    Converts text in to ascii to remove special characters, then converts back in to utf-8\n",
    "    '''\n",
    "    string = (unicodedata.normalize('NFKD', string.lower())\n",
    "            .encode('ascii', 'ignore') # ascii to reduce noise\n",
    "            .decode('utf-8', 'ignore') # decode using utf-8\n",
    "           )\n",
    "    string = re.sub(r\"[^a-z0-9\\s]\", '', string)\n",
    "     # Remove numbers from text\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string\n",
    "    \n",
    "\n",
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    extra_words=('accessing',\n",
    "     'according',\n",
    "     'account',\n",
    "     'accuracy',\n",
    "     'accurate',\n",
    "     'acknowledgement',\n",
    "     'acquired',\n",
    "     'across',\n",
    "     'activate',\n",
    "     'addition',\n",
    "     'additional',\n",
    "     'adhere',\n",
    "     'adheres',\n",
    "     'aim',\n",
    "     'al',\n",
    "     'along',\n",
    "     'also',\n",
    "     'alternative',\n",
    "     'anacona',\n",
    "     'anaconda',\n",
    "     'analyse',\n",
    "     'analysed',\n",
    "     'analysis',\n",
    "     'andor',\n",
    "     'answer',\n",
    "     'appearance',\n",
    "     'application',\n",
    "     'assetids',\n",
    "     'associated',\n",
    "     'assumption',\n",
    "     'attempt',\n",
    "     'author',\n",
    "     'automated',\n",
    "     'automatic',\n",
    "     'available',\n",
    "     'based',\n",
    "     'behavior',\n",
    "     'behaviour',\n",
    "     'benson',\n",
    "     'better',\n",
    "     'bias',\n",
    "     'biased',\n",
    "     'billie',\n",
    "     'birthdeath',\n",
    "     'bug',\n",
    "     'calculated',\n",
    "     'cannot',\n",
    "     'caper',\n",
    "     'capture',\n",
    "     'carried',\n",
    "     'cause',\n",
    "     'cc',\n",
    "     'cc ',\n",
    "     'cd',\n",
    "     'check',\n",
    "     'cite',\n",
    "     'citing',\n",
    "     'clone',\n",
    "     'closer',\n",
    "     'cloud',\n",
    "     'cloudquickplotcloudheadergetcamera',\n",
    "     'code',\n",
    "     'coma',\n",
    "     'commented',\n",
    "     'common',\n",
    "     'compared',\n",
    "     'complete',\n",
    "     'completeness',\n",
    "     'conda',\n",
    "     'consistently',\n",
    "     'console',\n",
    "     'contributing',\n",
    "     'conventionally',\n",
    "     'cool',\n",
    "     'copytxt',\n",
    "     'corescannerhypercloud',\n",
    "     'corescannerhypercloud ',\n",
    "     'corrected',\n",
    "     'correction',\n",
    "     'could',\n",
    "     'count',\n",
    "     'cpu',\n",
    "     'create',\n",
    "     'created',\n",
    "     'currently',\n",
    "     'daniel',\n",
    "     'data',\n",
    "     'database',\n",
    "     'dataimporterr',\n",
    "     'datasets',\n",
    "     'default',\n",
    "     'define',\n",
    "     'derivative',\n",
    "     'design',\n",
    "     'desired',\n",
    "     'detailed',\n",
    "     'dev',\n",
    "     'developingmd',\n",
    "     'different',\n",
    "     'difficult',\n",
    "     'dimensionality',\n",
    "     'directory',\n",
    "     'disable',\n",
    "     'disables',\n",
    "     'display',\n",
    "     'dissertation',\n",
    "     'diversitydependent',\n",
    "     'documentation',\n",
    "     'doe',\n",
    "     'download',\n",
    "     'downloading',\n",
    "     'dtilesets',\n",
    "     'due',\n",
    "     'earth',\n",
    "     'easily',\n",
    "     'efficiently',\n",
    "     'eg',\n",
    "     'empirical',\n",
    "     'end',\n",
    "     'enforce',\n",
    "     'entierty',\n",
    "     'enviroment',\n",
    "     'environment',\n",
    "     'equilibrium',\n",
    "     'error',\n",
    "     'estimate',\n",
    "     'estimation',\n",
    "     'et',\n",
    "     'even',\n",
    "     'example',\n",
    "     'except',\n",
    "     'explosion',\n",
    "     'exponentially',\n",
    "     'exponentiallydiversifying',\n",
    "     'extant',\n",
    "     'extend',\n",
    "     'factor',\n",
    "     'fast',\n",
    "     'feature',\n",
    "     'feel',\n",
    "     'file',\n",
    "     'find',\n",
    "     'fine',\n",
    "     'fix',\n",
    "     'following',\n",
    "     'format',\n",
    "     'foundation',\n",
    "     'free',\n",
    "     'function',\n",
    "     'functionssavesetsr',\n",
    "     'functionsuniformsamplingr',\n",
    "     'gdal',\n",
    "     'general',\n",
    "     'generate',\n",
    "     'generating',\n",
    "     'geological',\n",
    "     'geology',\n",
    "     'get',\n",
    "     'getting',\n",
    "     'git',\n",
    "     'github',\n",
    "     'gnu',\n",
    "     'google',\n",
    "     'ground',\n",
    "     'ha',\n",
    "     'happy',\n",
    "     'hardcoded',\n",
    "     'high',\n",
    "     'highresolution',\n",
    "     'history',\n",
    "     'hope',\n",
    "     'httplocalhost',\n",
    "     'httpsbetaswissgeolch',\n",
    "     'httpsgithubcomswissgeolngmgit',\n",
    "     'httpshylitereadthedocsioenlatestindexhtml',\n",
    "     'httpsopengameartorgcontenttemplateorangetexturepack',\n",
    "     'httpswwwgnuorglicenses',\n",
    "     'hylitergb',\n",
    "     'hyperclouds',\n",
    "     'id',\n",
    "     'idea',\n",
    "     'image',\n",
    "     'imagine',\n",
    "     'implemented',\n",
    "     'implied',\n",
    "     'import',\n",
    "     'inaccurate',\n",
    "     'included',\n",
    "     'includes',\n",
    "     'including',\n",
    "     'indicate',\n",
    "     'inferred',\n",
    "     'information',\n",
    "     'initialscreenspaceerror',\n",
    "     'inspector',\n",
    "     'install',\n",
    "     'installation',\n",
    "     'installed',\n",
    "     'integrated',\n",
    "     'integration',\n",
    "     'introduces',\n",
    "     'inverse',\n",
    "     'io',\n",
    "     'ioloadtestdatahypercloudplycloudquickplotcloudheadergetcamera',\n",
    "     'ioloadtestdataimagehdrimagequickplothylitergb',\n",
    "     'ioloadtestdatalibrarycsvlibquickplot',\n",
    "     'issue',\n",
    "     'json',\n",
    "     'jupyter',\n",
    "     'key',\n",
    "     'keyboard',\n",
    "     'keyboardlayouteditor',\n",
    "     'know',\n",
    "     'laboratory',\n",
    "     'launch',\n",
    "     'launching',\n",
    "     'layout',\n",
    "     'learning',\n",
    "     'least',\n",
    "     'length',\n",
    "     'level',\n",
    "     'lib',\n",
    "     'libquickplot',\n",
    "     'library',\n",
    "     'licencemd',\n",
    "     'license',\n",
    "     'limit',\n",
    "     'lineagecombining',\n",
    "     'list',\n",
    "     'local',\n",
    "     'localhost',\n",
    "     'localhost ',\n",
    "     'long',\n",
    "     'longheld',\n",
    "     'lorenz',\n",
    "     'machine',\n",
    "     'made',\n",
    "     'maintainerpackage',\n",
    "     'make',\n",
    "     'many',\n",
    "     'map',\n",
    "     'marineeumetazoacsv',\n",
    "     'mark',\n",
    "     'marker',\n",
    "     'marking',\n",
    "     'matplotlib',\n",
    "     'maximum',\n",
    "     'maximumscreenspaceerror',\n",
    "     'merchantability',\n",
    "     'method',\n",
    "     'mind',\n",
    "     'minimum',\n",
    "     'modify',\n",
    "     'multiscale',\n",
    "     'must',\n",
    "     'myr',\n",
    "     'myrs',\n",
    "     'navigate',\n",
    "     'navigation',\n",
    "     'need',\n",
    "     'new',\n",
    "     'next',\n",
    "     'ngm',\n",
    "     'nolimit',\n",
    "     'nolimitfalse',\n",
    "     'norequestrendermode',\n",
    "     'note',\n",
    "     'notebook',\n",
    "     'npm',\n",
    "     'number',\n",
    "     'numpy',\n",
    "     'occurrence',\n",
    "     'one',\n",
    "     'open',\n",
    "     'opencv',\n",
    "     'opening',\n",
    "     'openpit',\n",
    "     'opensource',\n",
    "     'operation',\n",
    "     'optimization',\n",
    "     'optional',\n",
    "     'order',\n",
    "     'originatorclose',\n",
    "     'ouput',\n",
    "     'outdoor',\n",
    "     'ownterrainfalse',\n",
    "     'oxford',\n",
    "     'package',\n",
    "     'parameter',\n",
    "     'partially',\n",
    "     'particular',\n",
    "     'past',\n",
    "     'pattern',\n",
    "     'pde',\n",
    "     'pdes',\n",
    "     'perform',\n",
    "     'performed',\n",
    "     'phytools',\n",
    "     'pip',\n",
    "     'placed',\n",
    "     'please',\n",
    "     'point',\n",
    "     'pointcloud',\n",
    "     'possible',\n",
    "     'potential',\n",
    "     'preform',\n",
    "     'preprocessing',\n",
    "     'prerequisitev',\n",
    "     'prerequisitewindowv',\n",
    "     'present',\n",
    "     'prevented',\n",
    "     'problem',\n",
    "     'processing',\n",
    "     'produce',\n",
    "     'produced',\n",
    "     'program',\n",
    "     'project',\n",
    "     'prompt',\n",
    "     'properly',\n",
    "     'provide',\n",
    "     'provided',\n",
    "     'proxy',\n",
    "     'public',\n",
    "     'publically',\n",
    "     'published',\n",
    "     'pull',\n",
    "     'purpose',\n",
    "     'python',\n",
    "     'quality',\n",
    "     'question',\n",
    "     'r',\n",
    "     'rather',\n",
    "     'raw',\n",
    "     'readme',\n",
    "     'received',\n",
    "     'recent',\n",
    "     'record',\n",
    "     'rectangle',\n",
    "     'redistribute',\n",
    "     'reduction',\n",
    "     'refer',\n",
    "     'reference',\n",
    "     'referred',\n",
    "     'reforester',\n",
    "     'regime',\n",
    "     'reinterpretation',\n",
    "     'report',\n",
    "     'repository',\n",
    "     'request',\n",
    "     'requires',\n",
    "     'research',\n",
    "     'resource',\n",
    "     'respectively',\n",
    "     'restrict',\n",
    "     'restriction',\n",
    "     'result',\n",
    "     'results',\n",
    "     'reults',\n",
    "     'review',\n",
    "     'rigorous',\n",
    "     'roger',\n",
    "     'run',\n",
    "     'running',\n",
    "     'said',\n",
    "     'sample',\n",
    "     'sampled',\n",
    "     'sampling',\n",
    "     'scan',\n",
    "     'scene',\n",
    "     'script',\n",
    "     'seamless',\n",
    "     'second',\n",
    "     'section',\n",
    "     'see',\n",
    "     'separated',\n",
    "     'server',\n",
    "     'set',\n",
    "     'setuppy',\n",
    "     'setuptools',\n",
    "     'significant',\n",
    "     'significantly',\n",
    "     'similarly',\n",
    "     'simple',\n",
    "     'slight',\n",
    "     'software',\n",
    "     'solved',\n",
    "     'source',\n",
    "     'specie',\n",
    "     'specific',\n",
    "     'specifically',\n",
    "     'sphere',\n",
    "     'start',\n",
    "     'started',\n",
    "     'stay',\n",
    "     'step',\n",
    "     'still',\n",
    "     'study',\n",
    "     'style',\n",
    "     'submit',\n",
    "     'sufficiently',\n",
    "     'suggests',\n",
    "     'supervised',\n",
    "     'sure',\n",
    "     'swiss',\n",
    "     'swissgeol',\n",
    "     'swissrectangle',\n",
    "     'swissrectanglefalse',\n",
    "     'swisstopo',\n",
    "     'take',\n",
    "     'technique',\n",
    "     'technology',\n",
    "     'template',\n",
    "     'templatelogistic',\n",
    "     'templatenotebooks',\n",
    "     'term',\n",
    "     'terminal',\n",
    "     'test',\n",
    "     'testdatahypercloudply',\n",
    "     'testdataimagehdr',\n",
    "     'testdatalibrarycsv',\n",
    "     'testing',\n",
    "     'texture',\n",
    "     'theoretically',\n",
    "     'thereby',\n",
    "     'thiele',\n",
    "     'thing',\n",
    "     'thompson',\n",
    "     'though',\n",
    "     'tidyverse',\n",
    "     'time',\n",
    "     'timeheterogeneous',\n",
    "     'tool',\n",
    "     'touchdirectly',\n",
    "     'true',\n",
    "     'try',\n",
    "     'trying',\n",
    "     'tuned',\n",
    "     'type',\n",
    "     'typing',\n",
    "     'ubiquity',\n",
    "     'understanding',\n",
    "     'unfortunately',\n",
    "     'unsupervised',\n",
    "     'unzip',\n",
    "     'url',\n",
    "     'us',\n",
    "     'use',\n",
    "     'used',\n",
    "     'userhylite'\n",
    "     'userhylite ',\n",
    "     'userhyliterequired',\n",
    "     'using',\n",
    "     'value',\n",
    "     'variety',\n",
    "     'vast',\n",
    "     'version',\n",
    "     'viewed',\n",
    "     'viewer',\n",
    "     'visual',\n",
    "     'wa',\n",
    "     'want',\n",
    "     'way',\n",
    "     'welcome',\n",
    "     'welcomed',\n",
    "     'widget',\n",
    "     'window',\n",
    "     'word',\n",
    "     'work',\n",
    "     'project',\n",
    "     'workflow')\n",
    "\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    #print(f\"Lenght of stopword list before:{len(stopword_list)}\")\n",
    "    stopword_list = set(stopword_list).union(set(extra_words))\n",
    "    #print(f\"Lenght of stopword list after:{len(stopword_list)}\")\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    return string_without_stopwords\n",
    "\n",
    "    \n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This function takes in a dataframe of text, cleans, tokenizes, lemmatizes, and removes stopwords\n",
    "    from that text, appending each step in the process to the dataframe.  It also appends a list of \n",
    "    words from each article as well as the total lenght.  \n",
    "    '''    \n",
    "\n",
    "    # Formatts repo contents to make them easier to read\n",
    "    df['text_cleaned'] = df.content.apply(basic_clean)\n",
    "    df['text_tokenized'] = df.text_cleaned.apply(tokenize)\n",
    "    df['text_lemmatized'] = df.text_tokenized.apply(lemmatize)\n",
    "    df['text_filtered'] = df.text_lemmatized.apply(remove_stopwords)\n",
    "    # Add column with list of words\n",
    "    words = [re.sub(r'([^a-z0-9\\s]|\\s.\\s)', '', doc).split() for doc in df.text_filtered]\n",
    "    df = pd.concat([df, pd.DataFrame({'words': words})], axis=1)\n",
    "    # Adds column with lenght of word list\n",
    "    df['doc_length'] = [len(wordlist) for wordlist in df.words]\n",
    "    df[['language','text_filtered','words','doc_length']]\n",
    "    # removing unpopular languages \n",
    "    language_list = ['JavaScript', 'R', 'Jupyter Notebook']\n",
    "    df = df[df.language.isin(language_list)]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>words</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite\\nhylite is an open-source python packag...</td>\n",
       "      <td>2020-11-27 17:31:07.762</td>\n",
       "      <td>hylite\\nhylite is an opensource python package...</td>\n",
       "      <td>hylite\\nhylite is an opensource python package...</td>\n",
       "      <td>hylite hylite is an opensource python package ...</td>\n",
       "      <td>hylite hylite imagery hyperspectral sensor fus...</td>\n",
       "      <td>[hylite, hylite, imagery, hyperspectral, senso...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Reforester\\nReforester, an R program that:\\n\\n...</td>\n",
       "      <td>2020-11-27 17:31:08.926</td>\n",
       "      <td>reforester\\nreforester an r program that\\n\\nus...</td>\n",
       "      <td>reforester\\nreforester an r program that\\n\\nus...</td>\n",
       "      <td>reforester reforester an r program that us a l...</td>\n",
       "      <td>logistic model simulated phylogenetic tree her...</td>\n",
       "      <td>[logistic, model, simulated, phylogenetic, tre...</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...</td>\n",
       "      <td>2020-11-27 17:31:09.532</td>\n",
       "      <td>swissgeol ngm\\na geology d viewer\\nswissgeol i...</td>\n",
       "      <td>swissgeol ngm\\na geology d viewer\\nswissgeol i...</td>\n",
       "      <td>swissgeol ngm a geology d viewer swissgeol is ...</td>\n",
       "      <td>cesiumjs adapt developing lava cesium ion cesi...</td>\n",
       "      <td>[cesiumjs, adapt, developing, lava, cesium, io...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Automatic Rock Core Sample Marker\\n\\nAs we kno...</td>\n",
       "      <td>2020-11-27 17:31:11.414</td>\n",
       "      <td>automatic rock core sample marker\\n\\nas we kno...</td>\n",
       "      <td>automatic rock core sample marker\\n\\nas we kno...</td>\n",
       "      <td>automatic rock core sample marker a we know th...</td>\n",
       "      <td>rock core ore ore core</td>\n",
       "      <td>[rock, core, ore, ore, core]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite\\nhylite is an open-source python packag...</td>\n",
       "      <td>2020-11-27 17:31:12.886</td>\n",
       "      <td>hylite\\nhylite is an opensource python package...</td>\n",
       "      <td>hylite\\nhylite is an opensource python package...</td>\n",
       "      <td>hylite hylite is an opensource python package ...</td>\n",
       "      <td>hylite hylite imagery hyperspectral sensor fus...</td>\n",
       "      <td>[hylite, hylite, imagery, hyperspectral, senso...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           language                                            content  \\\n",
       "0  Jupyter Notebook  hylite\\nhylite is an open-source python packag...   \n",
       "2                 R  Reforester\\nReforester, an R program that:\\n\\n...   \n",
       "3        JavaScript  Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...   \n",
       "6  Jupyter Notebook  Automatic Rock Core Sample Marker\\n\\nAs we kno...   \n",
       "8  Jupyter Notebook  hylite\\nhylite is an open-source python packag...   \n",
       "\n",
       "                     date                                       text_cleaned  \\\n",
       "0 2020-11-27 17:31:07.762  hylite\\nhylite is an opensource python package...   \n",
       "2 2020-11-27 17:31:08.926  reforester\\nreforester an r program that\\n\\nus...   \n",
       "3 2020-11-27 17:31:09.532  swissgeol ngm\\na geology d viewer\\nswissgeol i...   \n",
       "6 2020-11-27 17:31:11.414  automatic rock core sample marker\\n\\nas we kno...   \n",
       "8 2020-11-27 17:31:12.886  hylite\\nhylite is an opensource python package...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  hylite\\nhylite is an opensource python package...   \n",
       "2  reforester\\nreforester an r program that\\n\\nus...   \n",
       "3  swissgeol ngm\\na geology d viewer\\nswissgeol i...   \n",
       "6  automatic rock core sample marker\\n\\nas we kno...   \n",
       "8  hylite\\nhylite is an opensource python package...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  hylite hylite is an opensource python package ...   \n",
       "2  reforester reforester an r program that us a l...   \n",
       "3  swissgeol ngm a geology d viewer swissgeol is ...   \n",
       "6  automatic rock core sample marker a we know th...   \n",
       "8  hylite hylite is an opensource python package ...   \n",
       "\n",
       "                                       text_filtered  \\\n",
       "0  hylite hylite imagery hyperspectral sensor fus...   \n",
       "2  logistic model simulated phylogenetic tree her...   \n",
       "3  cesiumjs adapt developing lava cesium ion cesi...   \n",
       "6                             rock core ore ore core   \n",
       "8  hylite hylite imagery hyperspectral sensor fus...   \n",
       "\n",
       "                                               words  doc_length  \n",
       "0  [hylite, hylite, imagery, hyperspectral, senso...          55  \n",
       "2  [logistic, model, simulated, phylogenetic, tre...         322  \n",
       "3  [cesiumjs, adapt, developing, lava, cesium, io...          11  \n",
       "6                       [rock, core, ore, ore, core]           5  \n",
       "8  [hylite, hylite, imagery, hyperspectral, senso...          55  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_data(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of words for each language category and remove single letter words\n",
    "jupyter_words, js_words, r_words = explore.create_lang_word_list(df)\n",
    "# get the count of words by category\n",
    "jupyter_freq, js_freq, r_freq = explore.get_count_word_freq(jupyter_words, js_words, r_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hylite                     4176\n",
       "spectral                   1160\n",
       "wavelength                  696\n",
       "ioload                      696\n",
       "mapping                     696\n",
       "ore                         688\n",
       "hyperspectral               464\n",
       "imagery                     464\n",
       "rock                        460\n",
       "core                        456\n",
       "imagequickplothylitergb     232\n",
       "visualised                  232\n",
       "radiometrically             232\n",
       "polymorphism                232\n",
       "sensor                      232\n",
       "fusing                      232\n",
       "userhylite                  232\n",
       "touchdirectly               232\n",
       "visualisation               232\n",
       "corescannerhypercloud       232\n",
       "visualising                 232\n",
       "classification              232\n",
       "multisensor                 232\n",
       "mine                        232\n",
       "measurement                 232\n",
       "angle                       232\n",
       "spectrum                    232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupyter_freq.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cesium        458\n",
       "lava          458\n",
       "cesiumjs      229\n",
       "rendering     229\n",
       "terrain       229\n",
       "ion           229\n",
       "adapt         229\n",
       "cesiumion     229\n",
       "developing    229\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_freq.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copyingtxt        232\n",
       "scale             232\n",
       "gradient          232\n",
       "supervisor        232\n",
       "tested            232\n",
       "interpretation    232\n",
       "introduced        232\n",
       "combining         232\n",
       "unpreserved       232\n",
       "fitness           232\n",
       "postcambrian      232\n",
       "vary              232\n",
       "host              232\n",
       "either            232\n",
       "span              232\n",
       "diversified       232\n",
       "day               232\n",
       "university        232\n",
       "various           232\n",
       "copy              232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_freq.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-e54b23c1535c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e54b23c1535c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ioload                      696\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ioload                      696\n",
    "touchdirectly               232\n",
    "imagequickplothylitergb     232\n",
    "visualising                 232\n",
    "radiometrically             232\n",
    "userhylite                  232\n",
    "spectrum                    232\n",
    "mine                        232\n",
    "visualisation               232\n",
    "angle                       232\n",
    "corescannerhypercloud       232\n",
    "visualised                  232\n",
    "multisensor                 232\n",
    "throughout              232\n",
    "gradient                232\n",
    "creator                 232\n",
    "close                   232\n",
    "integral                232\n",
    "intended                232\n",
    "degree                  232\n",
    "mostnotably             232\n",
    "computes                232\n",
    "tested                  232\n",
    "fitness                 232\n",
    "yet                     232\n",
    "mainuniformsamplingr    232\n",
    "survived                232\n",
    "either                  232\n",
    "cambrian                232\n",
    "straightforward         232\n",
    "systematic              232\n",
    "introduced              232\n",
    "whether                 232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    extra_words=('project','workflow','I')\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    \n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_list = set(stopword_list).union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = text.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =(\" I a hat this project but and i have no workflow purple unicorn apple fan open square\")\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud jupyter_notebook\n",
    "plt.figure(figsize=(10,10))\n",
    "text = jupyter_words\n",
    "wc = WordCloud(background_color=\"white\",\n",
    "               max_words=2000, max_font_size=224,\n",
    "               random_state=42)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud js\n",
    "plt.figure(figsize=(10,10))\n",
    "text = js_words\n",
    "wc = WordCloud(background_color=\"white\",\n",
    "               max_words=2000, max_font_size=224,\n",
    "               random_state=42)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud R\n",
    "plt.figure(figsize=(10,10))\n",
    "text = r_words\n",
    "wc = WordCloud(background_color=\"white\",\n",
    "               max_words=2000, max_font_size=224,\n",
    "               random_state=42)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
