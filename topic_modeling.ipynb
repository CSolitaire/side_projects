{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import pandas as pd\n",
    "from string import digits\n",
    "import explore\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite\\nhylite is an open-source python packag...</td>\n",
       "      <td>2020-11-27 17:31:07.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nWebviz subsurface\\n\\nâœ¨ðŸ‘“ Live demo ...</td>\n",
       "      <td>2020-11-27 17:31:08.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Reforester\\nReforester, an R program that:\\n\\n...</td>\n",
       "      <td>2020-11-27 17:31:08.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...</td>\n",
       "      <td>2020-11-27 17:31:09.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodel-2-3dweb\\n\\nGenerates 3D web versions ...</td>\n",
       "      <td>2020-11-27 17:31:10.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           language                                            content  \\\n",
       "0  Jupyter Notebook  hylite\\nhylite is an open-source python packag...   \n",
       "1            Python  \\n\\n\\n\\n\\n\\nWebviz subsurface\\n\\nâœ¨ðŸ‘“ Live demo ...   \n",
       "2                 R  Reforester\\nReforester, an R program that:\\n\\n...   \n",
       "3        JavaScript  Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...   \n",
       "4            Python  geomodel-2-3dweb\\n\\nGenerates 3D web versions ...   \n",
       "\n",
       "                     date  \n",
       "0 2020-11-27 17:31:07.762  \n",
       "1 2020-11-27 17:31:08.305  \n",
       "2 2020-11-27 17:31:08.926  \n",
       "3 2020-11-27 17:31:09.532  \n",
       "4 2020-11-27 17:31:10.206  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_github_geology_results(cached=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Clean Data Function ###############################\n",
    "\n",
    "def basic_clean(string):\n",
    "    '''\n",
    "    Converts text in to ascii to remove special characters, then converts back in to utf-8\n",
    "    '''\n",
    "    string = (unicodedata.normalize('NFKD', string.lower())\n",
    "            .encode('ascii', 'ignore') # ascii to reduce noise\n",
    "            .decode('utf-8', 'ignore') # decode using utf-8\n",
    "           )\n",
    "    string = re.sub(r\"[^a-z0-9\\s]\", '', string)\n",
    "     # Remove numbers from text\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    return string\n",
    "    \n",
    "\n",
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    #print(f\"Lenght of stopword list before:{len(stopword_list)}\")\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    return string_without_stopwords\n",
    "\n",
    "    \n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This function takes in a dataframe of text, cleans, tokenizes, lemmatizes, and removes stopwords\n",
    "    from that text, appending each step in the process to the dataframe.  It also appends a list of \n",
    "    words from each article as well as the total lenght.  \n",
    "    '''    \n",
    "\n",
    "    # Formatts repo contents to make them easier to read\n",
    "    df['text_cleaned'] = df.content.apply(basic_clean)\n",
    "    df['text_tokenized'] = df.text_cleaned.apply(tokenize)\n",
    "    df['text_lemmatized'] = df.text_tokenized.apply(lemmatize)\n",
    "    df['text_filtered'] = df.text_lemmatized.apply(remove_stopwords)\n",
    "    # Add column with list of words\n",
    "    words = [re.sub(r'([^a-z0-9\\s]|\\s.\\s)', '', doc).split() for doc in df.text_filtered]\n",
    "    df = pd.concat([df, pd.DataFrame({'words': words})], axis=1)\n",
    "    # Adds column with lenght of word list\n",
    "    df['doc_length'] = [len(wordlist) for wordlist in df.words]\n",
    "    df = df[['language','text_filtered','words','doc_length']]\n",
    "    \n",
    "    # removing unpopular languages \n",
    "    #language_list = ['JavaScript', 'R', 'Jupyter Notebook']\n",
    "    #df = df[df.language.isin(language_list)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>words</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite hylite opensource python package prepro...</td>\n",
       "      <td>[hylite, hylite, opensource, python, package, ...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>webviz subsurface live demo application introd...</td>\n",
       "      <td>[webviz, subsurface, live, demo, application, ...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>reforester reforester r program us logistic bi...</td>\n",
       "      <td>[reforester, reforesterprogram, us, logistic, ...</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>swissgeol ngm geology viewer swissgeol new geo...</td>\n",
       "      <td>[swissgeol, ngm, geology, viewer, swissgeol, n...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodeldweb generates web version geological ...</td>\n",
       "      <td>[geomodeldweb, generates, web, version, geolog...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite hylite opensource python package prepro...</td>\n",
       "      <td>[hylite, hylite, opensource, python, package, ...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Python</td>\n",
       "      <td>webviz subsurface live demo application introd...</td>\n",
       "      <td>[webviz, subsurface, live, demo, application, ...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>R</td>\n",
       "      <td>reforester reforester r program us logistic bi...</td>\n",
       "      <td>[reforester, reforesterprogram, us, logistic, ...</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>swissgeol ngm geology viewer swissgeol new geo...</td>\n",
       "      <td>[swissgeol, ngm, geology, viewer, swissgeol, n...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodeldweb generates web version geological ...</td>\n",
       "      <td>[geomodeldweb, generates, web, version, geolog...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              language                                      text_filtered  \\\n",
       "0     Jupyter Notebook  hylite hylite opensource python package prepro...   \n",
       "1               Python  webviz subsurface live demo application introd...   \n",
       "2                    R  reforester reforester r program us logistic bi...   \n",
       "3           JavaScript  swissgeol ngm geology viewer swissgeol new geo...   \n",
       "4               Python  geomodeldweb generates web version geological ...   \n",
       "...                ...                                                ...   \n",
       "1836  Jupyter Notebook  hylite hylite opensource python package prepro...   \n",
       "1837            Python  webviz subsurface live demo application introd...   \n",
       "1838                 R  reforester reforester r program us logistic bi...   \n",
       "1839        JavaScript  swissgeol ngm geology viewer swissgeol new geo...   \n",
       "1840            Python  geomodeldweb generates web version geological ...   \n",
       "\n",
       "                                                  words  doc_length  \n",
       "0     [hylite, hylite, opensource, python, package, ...         300  \n",
       "1     [webviz, subsurface, live, demo, application, ...         261  \n",
       "2     [reforester, reforesterprogram, us, logistic, ...         771  \n",
       "3     [swissgeol, ngm, geology, viewer, swissgeol, n...         120  \n",
       "4     [geomodeldweb, generates, web, version, geolog...         174  \n",
       "...                                                 ...         ...  \n",
       "1836  [hylite, hylite, opensource, python, package, ...         300  \n",
       "1837  [webviz, subsurface, live, demo, application, ...         261  \n",
       "1838  [reforester, reforesterprogram, us, logistic, ...         771  \n",
       "1839  [swissgeol, ngm, geology, viewer, swissgeol, n...         120  \n",
       "1840  [geomodeldweb, generates, web, version, geolog...         174  \n",
       "\n",
       "[1841 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
