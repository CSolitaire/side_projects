{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire\n",
    "import prepare\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import prepare\n",
    "import acquire\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call In DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1841 entries, 0 to 1840\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   language  1841 non-null   object        \n",
      " 1   content   1841 non-null   object        \n",
      " 2   date      1841 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 57.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>hylite\\nhylite is an open-source python packag...</td>\n",
       "      <td>2020-11-27 17:31:07.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nWebviz subsurface\\n\\nâœ¨ðŸ‘“ Live demo ...</td>\n",
       "      <td>2020-11-27 17:31:08.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Reforester\\nReforester, an R program that:\\n\\n...</td>\n",
       "      <td>2020-11-27 17:31:08.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...</td>\n",
       "      <td>2020-11-27 17:31:09.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>geomodel-2-3dweb\\n\\nGenerates 3D web versions ...</td>\n",
       "      <td>2020-11-27 17:31:10.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           language                                            content  \\\n",
       "0  Jupyter Notebook  hylite\\nhylite is an open-source python packag...   \n",
       "1            Python  \\n\\n\\n\\n\\n\\nWebviz subsurface\\n\\nâœ¨ðŸ‘“ Live demo ...   \n",
       "2                 R  Reforester\\nReforester, an R program that:\\n\\n...   \n",
       "3        JavaScript  Swissgeol NGM\\nA Geology 3D viewer\\nSwissgeol ...   \n",
       "4            Python  geomodel-2-3dweb\\n\\nGenerates 3D web versions ...   \n",
       "\n",
       "                     date  \n",
       "0 2020-11-27 17:31:07.762  \n",
       "1 2020-11-27 17:31:08.305  \n",
       "2 2020-11-27 17:31:08.926  \n",
       "3 2020-11-27 17:31:09.532  \n",
       "4 2020-11-27 17:31:10.206  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_github_geology_results(cached=True)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python              463\n",
       "Jupyter Notebook    460\n",
       "R                   232\n",
       "TypeScript          229\n",
       "JavaScript          229\n",
       "Batchfile           228\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean\n",
    "df = prepare.prep_data(df, 'content', extra_words=[], exclude_words=[])\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ave Length of Readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_doc_length = round(mean(df[df.language == 'Python'].doc_length), 2)\n",
    "jupyter_doc_length = round(mean(df[df.language == 'Jupyter Notebook'].doc_length),2)\n",
    "r_doc_length = round(mean(df[df.language == 'R'].doc_length),2)\n",
    "javascript_doc_length = round(mean(df[df.language == 'JavaScript'].doc_length),2)\n",
    "typescript_doc_length = round(mean(df[df.language == 'TypeScript'].doc_length),2)\n",
    "batchfile_doc_length = round(mean(df[df.language == 'Batchfile'].doc_length),2)\n",
    "\n",
    "print(f'The average word length of the python repositories is {python_doc_length}')\n",
    "print(f'The average word length of the jupyter repositories is {jupyter_doc_length}')\n",
    "print(f'The average word length of the r repositories is {r_doc_length}')\n",
    "print(f'The average word length of the javascript repositories is {javascript_doc_length}')\n",
    "print(f'The average word length of the typescript repositories is {typescript_doc_length}')\n",
    "print(f'The average word length of the batchfile repositories is {batchfile_doc_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore List of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of words\n",
    "python_words = ' '.join(df[df.language=='Python'].lemmatized)\n",
    "jupyter_words = ' '.join(df[df.language=='Jupyter Notebook'].lemmatized)\n",
    "r_words = ' '.join(df[df.language=='R'].lemmatized)\n",
    "typescript_words = ' '.join(df[df.language=='TypeScript'].lemmatized)\n",
    "javascript_words = ' '.join(df[df.language=='JavaScript'].lemmatized)\n",
    "batchfile_words = ' '.join(df[df.language=='Batchfile'].lemmatized)\n",
    "all_words = ' '.join(df.lemmatized)\n",
    "\n",
    "# remove spaces\n",
    "python_words = re.sub(r'\\s.\\s', '', python_words)\n",
    "jupyter_words = re.sub(r'\\s.\\s', '', jupyter_words)\n",
    "r_words = re.sub(r'\\s.\\s', '', r_words)\n",
    "typescript_words = re.sub(r'\\s.\\s', '', typescript_words)\n",
    "javascript_words = re.sub(r'\\s.\\s', '', javascript_words)\n",
    "batchfile_words = re.sub(r'\\s.\\s', '', batchfile_words)\n",
    "all_words = re.sub(r'\\s.\\s', '', all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcounts\n",
    "\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "jupyter_freq = pd.Series(jupyter_words.split()).value_counts()\n",
    "r_freq = pd.Series(r_words.split()).value_counts()\n",
    "typescript_freq = pd.Series(typescript_words.split()).value_counts()\n",
    "javascript_freq = pd.Series(javascript_words.split()).value_counts()\n",
    "batchfile_freq = pd.Series(batchfile_words.split()).value_counts()\n",
    "all_freq = pd.Series(all_words.split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to compare most frequent words\n",
    "\n",
    "word_counts = (pd.concat([all_freq, python_freq, jupyter_freq, r_freq, typescript_freq, javascript_freq, batchfile_freq], axis=1, sort=True)\n",
    "               .set_axis(['all', 'python', 'jupyter', 'r', 'typescript', 'javascript', 'batchfile'], axis=1, inplace=False)\n",
    "               .fillna(0)\n",
    "               .apply(lambda s: s.astype(int))\n",
    "              )\n",
    "\n",
    "word_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the percentage of the term in tech vs. sports vs. entertainment\n",
    "(word_counts.assign(p_python = word_counts.python/word_counts['all'], \n",
    "                   p_jupyter = word_counts.jupyter/word_counts['all'],\n",
    "                   p_r = word_counts.r/word_counts['all'],\n",
    "                   p_typescript = word_counts.typescript/word_counts['all'],\n",
    "                   p_javascript = word_counts.javascript/word_counts['all'],\n",
    "                   p_batchfile = word_counts.batchfile/word_counts['all'])\n",
    " .sort_values(by='all')[['p_python', 'p_jupyter', 'p_r','p_typescript','p_javascript','p_batchfile']]\n",
    " .tail(20)\n",
    " .sort_values('p_python')\n",
    " .plot.barh(stacked=True, figsize = (20,10))\n",
    ")\n",
    "\n",
    "plt.title(\"Proportion of 20 most common keywords in GitHub Geology README Files\", fontsize = 20)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud python\n",
    "plt.figure(figsize=(10,10))\n",
    "text = python_words\n",
    "wc = WordCloud(background_color=\"white\",\n",
    "               max_words=2000, max_font_size=224,\n",
    "               random_state=42)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of bigrams\n",
    "ham_bigrams = pd.Series(list(nltk.ngrams(ham_words.split(), 2))).value_counts().hea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addd code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
