{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapper Jobs: Monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nurse, TBI Clinical Data Specialist\n",
      "Vista Defense Technologies, LLC\n",
      "Fort Sam Houston, TX\n",
      "\n",
      "Data Engineer\n",
      "WinCorp Solutions\n",
      "San Antonio, TX\n",
      "\n",
      "Data Scientist\n",
      "Alaka`ina Foundation Family of Companies\n",
      "San Antonio, TX\n",
      "\n",
      "Data Engineer\n",
      "Apex Systems\n",
      "San Antonio, TX\n",
      "\n",
      "LEAD COMPUTER SCIENTIST - SR. COMPUTER SCIENTIST - SPACE DATA SYSTEMS\n",
      "Southwest Research Institute\n",
      "San Antonio, TX\n",
      "\n",
      "Sr Data Entry Operator\n",
      "Randstad\n",
      "San Antonio, TX\n",
      "\n",
      "Sr. Data Engineer\n",
      "Randstad Technologies\n",
      "San Antonio, TX\n",
      "\n",
      "Data Entry Specialist\n",
      "Tri-Starr Personnel\n",
      "San Antonio, TX\n",
      "\n",
      "Data Control Clerk\n",
      "System One\n",
      "San Antonio, TX\n",
      "\n",
      "Social Media Specialist II\n",
      "CHRISTUS Health\n",
      "San Antonio, TX\n",
      "\n",
      "Aircraft Sheetmetal Mechanic\n",
      "Apollo Professional Solutions\n",
      "San Antonio, CA\n",
      "\n",
      "Veterinary Technician - 000210\n",
      "Banfield Pet Hospital\n",
      "San Antonio, TX\n",
      "\n",
      "Junior .Net Developer\n",
      "CyberCoders\n",
      "San Antonio, TX\n",
      "\n",
      "Contact Center Trainer\n",
      "OKIN BPS\n",
      "San Antonio, TX\n",
      "\n",
      "Bookkeeper\n",
      "Ramstin III LTD\n",
      "SAN ANTONIO, TX\n",
      "\n",
      "Operations Manager\n",
      "Phyllis Browning Company\n",
      "San Antonio, TX\n",
      "\n",
      "Marketing Communications Specialist\n",
      "Texas Biomedical Research Institute\n",
      "San Antonio, TX\n",
      "\n",
      "Systems Technician\n",
      "Air Force Federal Credit Union\n",
      "San Antonio, TX\n",
      "\n",
      "Electronic Assembler and QC\n",
      "Autotest Co. (www.autotest.com)\n",
      "SAN ANTONIO, TX\n",
      "\n",
      "Fence Technician\n",
      "United Site Services\n",
      "San Antonio, TX\n",
      "\n",
      "Imaging Specialist\n",
      "CorTech LLC\n",
      "San Antonio, TX\n",
      "\n",
      "Internet Analyst   Work From Home - Spanish speakers in the US!\n",
      "Appen Butler Hill Inc.\n",
      "San Antonio, TX\n",
      "\n",
      "Business Transformation Consultant\n",
      "Definitive Logic\n",
      "San Antonio, TX\n",
      "\n",
      "Database Administrator\n",
      "Seabrook Solutions\n",
      "Schertz, TX\n",
      "\n",
      "Telecommunications Network Help Desk\n",
      "Global Commerce and Services, LLC\n",
      "Lackland A F B, TX\n",
      "\n",
      "Machine Learning Software Engineer\n",
      "Samiti Technology Solutions and Services Private Limited\n",
      "San Antonio, TX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "job_type = \"data\"\n",
    "loc = \"San Antonio, TX\"\n",
    "\n",
    "URL = f\"https://www.monster.com/jobs/search/?q={job_type}\\\n",
    "        &where= {loc}\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"ResultsContainer\")\n",
    "\n",
    "# Look for Python jobs\n",
    "python_jobs = results.find_all(\"h2\", string=lambda t: \"python\" in t.lower())\n",
    "for p_job in python_jobs:\n",
    "    link = p_job.find(\"a\")[\"href\"]\n",
    "    print(p_job.text.strip())\n",
    "    print(f\"Apply here: {link}\\n\")\n",
    "\n",
    "# Print out all available jobs from the scraped webpage\n",
    "job_elems = results.find_all(\"section\", class_=\"card-content\")\n",
    "for job_elem in job_elems:\n",
    "    title_elem = job_elem.find(\"h2\", class_=\"title\")\n",
    "    company_elem = job_elem.find(\"div\", class_=\"company\")\n",
    "    location_elem = job_elem.find(\"div\", class_=\"location\")\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    print(title_elem.text.strip())\n",
    "    print(company_elem.text.strip())\n",
    "    print(location_elem.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapper Jobs: Seven Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f784f7fc4b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Look for jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"data\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "emp_type = \"education\"\n",
    "loc = \"any\"\n",
    "\n",
    "URL = f\"https://jobs.sevendaysvt.com/browse-jobs/?search_keywords={emp_type}&search_location={any}#.X0UFWElOnOQ\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"container\")\n",
    "\n",
    "# Look for jobs\n",
    "jobs = results.find_all(\"h2\", string=lambda t: \"data\" in t.lower())\n",
    "for job in jobs:\n",
    "    link = job.find(\"a\")[\"href\"]\n",
    "    print(job.text.strip())\n",
    "    print(f\"Apply here: {link}\\n\")\n",
    "\n",
    "# Print out all available jobs from the scraped webpage\n",
    "job_elems = results.find_all(\"section\", class_=\"card-content\")\n",
    "for job_elem in job_elems:\n",
    "    title_elem = job_elem.find(\"h2\", class_=\"title\")\n",
    "    company_elem = job_elem.find(\"div\", class_=\"company\")\n",
    "    location_elem = job_elem.find(\"div\", class_=\"location\")\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    print(title_elem.text.strip())\n",
    "    print(company_elem.text.strip())\n",
    "    print(location_elem.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
