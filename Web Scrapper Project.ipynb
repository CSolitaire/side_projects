{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapper Jobs: Monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Data Scientist\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "VP, DevOps\n",
      "Verint Systems, Inc.\n",
      "Montpelier, VT\n",
      "\n",
      "Implementations Analyst, Senior\n",
      "Fiserv\n",
      "Burlington, VT\n",
      "\n",
      "Solutions Architect - Data\n",
      "Sirius Computer Solutions\n",
      "Montpelier, VT\n",
      "\n",
      "Senior Database Engineer - Louisville, KY or Work at Home\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "Principal Software Engineer\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "Senior Business Intelligence Engineer\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "Lead Business Intelligence Engineer\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "Lead of Cybersecurity Data Protection & Analytics\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n",
      "Wellness Associate Actuary\n",
      "Humana\n",
      "Montpelier, VT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "URL = \"https://www.monster.com/jobs/search/?q=Data-Science\\\n",
    "        &where= Vermont\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"ResultsContainer\")\n",
    "\n",
    "# Look for Python jobs\n",
    "python_jobs = results.find_all(\"h2\", string=lambda t: \"python\" in t.lower())\n",
    "for p_job in python_jobs:\n",
    "    link = p_job.find(\"a\")[\"href\"]\n",
    "    print(p_job.text.strip())\n",
    "    print(f\"Apply here: {link}\\n\")\n",
    "\n",
    "# Print out all available jobs from the scraped webpage\n",
    "job_elems = results.find_all(\"section\", class_=\"card-content\")\n",
    "for job_elem in job_elems:\n",
    "    title_elem = job_elem.find(\"h2\", class_=\"title\")\n",
    "    company_elem = job_elem.find(\"div\", class_=\"company\")\n",
    "    location_elem = job_elem.find(\"div\", class_=\"location\")\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    print(title_elem.text.strip())\n",
    "    print(company_elem.text.strip())\n",
    "    print(location_elem.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapper Jobs: Seven Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f784f7fc4b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Look for jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"data\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "emp_type = \"education\"\n",
    "loc = \"any\"\n",
    "\n",
    "URL = f\"https://jobs.sevendaysvt.com/browse-jobs/?search_keywords={emp_type}&search_location={any}#.X0UFWElOnOQ\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"container\")\n",
    "\n",
    "# Look for jobs\n",
    "jobs = results.find_all(\"h2\", string=lambda t: \"data\" in t.lower())\n",
    "for job in jobs:\n",
    "    link = job.find(\"a\")[\"href\"]\n",
    "    print(job.text.strip())\n",
    "    print(f\"Apply here: {link}\\n\")\n",
    "\n",
    "# Print out all available jobs from the scraped webpage\n",
    "job_elems = results.find_all(\"section\", class_=\"card-content\")\n",
    "for job_elem in job_elems:\n",
    "    title_elem = job_elem.find(\"h2\", class_=\"title\")\n",
    "    company_elem = job_elem.find(\"div\", class_=\"company\")\n",
    "    location_elem = job_elem.find(\"div\", class_=\"location\")\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    print(title_elem.text.strip())\n",
    "    print(company_elem.text.strip())\n",
    "    print(location_elem.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
